{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, a modular implementation of preprocessing steps for Sentinel-1A Dual Polarization Ground Range Detected (GRD) High Resolution (HR) data is performed.\n"
      ],
      "metadata": {
        "id": "8zq2k4yRGKeK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset Details**\n",
        "\n",
        "    Name: Sentinel-1 Dataset\n",
        "    Provider: European Space Agency (ESA)\n",
        "    Data Range: 2015-2022\n",
        "    Data Type: Synthetic Aperture Radar (SAR) imagery\n",
        "    Purpose: Flood detection analysis and development of a machine learning model for floodwater segmentation and early warning system.\n",
        "    Access: The dataset can be accessed through the ESA's Sentinels Scientific Data Hub."
      ],
      "metadata": {
        "id": "j6D_f3GDqQHg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Steps are discusssed below in brief:**\n",
        "\n",
        "    1. Radiometric Calibration: Sentinel-1A data is provided in Digital Numbers (DN), which needs to be converted to calibrated power values in decibels (dB). This is done using the calibration parameters provided by the European Space Agency (ESA).\n",
        "\n",
        "    2. Multilooking: The raw data is in single-look format, which means that each pixel represents the radar response from a single area on the ground. Multilooking is a technique to combine multiple adjacent pixels to reduce the noise and improve the spatial resolution. It also helps to reduce speckle, which is a multiplicative noise in radar images.\n",
        "\n",
        "    3. Speckle Filtering: Speckle filtering is done to reduce the noise introduced by the radar signal. There are several speckle filtering techniques available, such as Lee filter, Gamma filter, and Median filter.\n",
        "\n",
        "    4. Geocoding: Geocoding is the process of converting the radar coordinates to geographic coordinates. This is done by applying a mathematical transformation to the data using the metadata provided by ESA.\n",
        "\n",
        "    5. Subsetting: Subsetting is the process of selecting a region of interest from the entire scene. This is done to reduce the data size and processing time.\n",
        "\n",
        "    6. Terrain Correction: Terrain correction is a process of correcting for the topographic effects on the radar signal. This is done to remove the distortions caused by the varying elevation of the ground surface. The corrected data is referred to as the backscatter coefficient, which represents the amount of radar energy that is scattered back to the sensor from the ground."
      ],
      "metadata": {
        "id": "3_PBltJkoJlL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: The above steps may vary depending on the specific application and requirements. \n",
        "\n",
        "For flood monitoring, it may be necessary to skip the **terrain correction** step as the elevation changes caused by floods may also be of interest. \n",
        "\n",
        "Further, **Geocoding, subsetting, and multilooking** are preprocessing steps that are typically performed on SAR data to correct for geometric distortions, reduce noise, and enhance the resolution of the images. However, in the context of flood mapping, these steps may not be necessary or may not provide significant benefits."
      ],
      "metadata": {
        "id": "pd1Wf6Y-o3nA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#installing requirements\n",
        "!pip install rasterio\n",
        "!pip install earthpy"
      ],
      "metadata": {
        "id": "wckGBBVBGmRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from osgeo import gdal\n",
        "import rasterio as rio\n",
        "from skimage.filters import median\n",
        "import earthpy.plot as ep\n",
        "import glob\n",
        "from affine import Affine"
      ],
      "metadata": {
        "id": "ETyA6yiAsvNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "FOVlc8Mz431L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reads in SENTINEL-1A_DUAL_POL_GRD_HIGH_RES data from the given path.\n",
        "#Returns a tuple of two numpy arrays representing VV and VH polarization images.\n",
        "\n",
        "def read_data(path, vv_file_name, vh_file_name):\n",
        "    # Locate the VV and VH .tif files\n",
        "    vv_path = os.path.join(path, vv_file_name)\n",
        "    vh_path = os.path.join(path, vh_file_name)\n",
        "    \n",
        "    # Open the VV and VH images using gdal\n",
        "    vv_dataset = gdal.Open(vv_path)\n",
        "    vh_dataset = gdal.Open(vh_path)\n",
        "    \n",
        "    # Get the size of the image\n",
        "    rows, cols = vv_dataset.RasterYSize, vv_dataset.RasterXSize\n",
        "    \n",
        "    # Define block size for reading in data\n",
        "    block_size = 512\n",
        "    \n",
        "    # Create empty lists to store VV and VH blocks\n",
        "    vv_blocks, vh_blocks = [], []\n",
        "    \n",
        "    # Read in VV and VH data in blocks\n",
        "    for i in range(0, rows, block_size):\n",
        "        for j in range(0, cols, block_size):\n",
        "            vv_block = vv_dataset.ReadAsArray(j, i, block_size, block_size)\n",
        "            vh_block = vh_dataset.ReadAsArray(j, i, block_size, block_size)\n",
        "            \n",
        "            if vv_block is not None and vh_block is not None:\n",
        "                vv_blocks.append(vv_block)\n",
        "                vh_blocks.append(vh_block)\n",
        "    \n",
        "    # Concatenate VV and VH blocks to create final arrays\n",
        "    vv = np.concatenate(vv_blocks, axis=0)\n",
        "    vh = np.concatenate(vh_blocks, axis=0)\n",
        "    \n",
        "    # Close the datasets\n",
        "    vv_dataset = None\n",
        "    vh_dataset = None\n",
        "    \n",
        "    return vv, vh"
      ],
      "metadata": {
        "id": "13_a8ew0famD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applies radiometric calibration to the VV and VH polarization images,\n",
        "# block by block, using the calibration factors provided by the sensor.\n",
        "\n",
        "def apply_calibration(vv, vh, block_size=512):\n",
        "    # Calibration factors for VV and VH images\n",
        "    k1_vv = -84.02\n",
        "    k2_vv = 0.62\n",
        "    k1_vh = -81.03\n",
        "    k2_vh = 0.64\n",
        "    \n",
        "    # Get input array shape\n",
        "    rows, cols = vv.shape\n",
        "    \n",
        "    # Create output arrays\n",
        "    calibrated_vv = np.zeros((rows, cols), dtype=np.uint16)\n",
        "    calibrated_vh = np.zeros((rows, cols), dtype=np.uint16)\n",
        "    \n",
        "    # Apply calibration to each block of the input arrays\n",
        "    for i in range(0, rows, block_size):\n",
        "        for j in range(0, cols, block_size):\n",
        "            vv_block = vv[i:i+block_size, j:j+block_size]\n",
        "            vh_block = vh[i:i+block_size, j:j+block_size]\n",
        "            \n",
        "            # Apply calibration to block\n",
        "            vv_block = (vv_block * k2_vv + k1_vv).astype(np.uint16)\n",
        "            vh_block = (vh_block * k2_vh + k1_vh).astype(np.uint16)\n",
        "            \n",
        "            # Save calibrated block to output arrays\n",
        "            calibrated_vv[i:i+block_size, j:j+block_size] = vv_block\n",
        "            calibrated_vh[i:i+block_size, j:j+block_size] = vh_block\n",
        "    \n",
        "    return calibrated_vv, calibrated_vh"
      ],
      "metadata": {
        "id": "01m8Rw0lyeuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#optimised-version\n",
        "\n",
        "#Applies radiometric calibration to the VV and VH polarization images,\n",
        "#block by block, using the calibration factors provided by the sensor.\n",
        "\n",
        "def apply_calibration2(path, vv_file_name, vh_file_name, block_size=512):\n",
        "    # Calibration factors for VV and VH images\n",
        "    k1_vv = -84.02\n",
        "    k2_vv = 0.62\n",
        "    k1_vh = -81.03\n",
        "    k2_vh = 0.64\n",
        "    \n",
        "    # Open the VV and VH images using gdal\n",
        "    vv_path = os.path.join(path, vv_file_name)\n",
        "    vh_path = os.path.join(path, vh_file_name)\n",
        "    vv_dataset = gdal.Open(vv_path)\n",
        "    vh_dataset = gdal.Open(vh_path)\n",
        "    \n",
        "    # Get the size of the image\n",
        "    rows, cols = vv_dataset.RasterYSize, vv_dataset.RasterXSize\n",
        "    \n",
        "    # Create output arrays\n",
        "    calibrated_vv = np.zeros((rows, cols), dtype=np.uint16)\n",
        "    calibrated_vh = np.zeros((rows, cols), dtype=np.uint16)\n",
        "    \n",
        "    # Apply calibration to each block of the input arrays\n",
        "    for i in range(0, rows, block_size):\n",
        "        for j in range(0, cols, block_size):\n",
        "            # Read in a block of data\n",
        "            vv_block = vv_dataset.ReadAsArray(j, i, block_size, block_size)\n",
        "            vh_block = vh_dataset.ReadAsArray(j, i, block_size, block_size)\n",
        "            \n",
        "            if vv_block is not None and vh_block is not None:\n",
        "                # Apply calibration to block\n",
        "                vv_block = (vv_block * k2_vv + k1_vv).astype(np.uint16)\n",
        "                vh_block = (vh_block * k2_vh + k1_vh).astype(np.uint16)\n",
        "                \n",
        "                # Save calibrated block to output arrays\n",
        "                calibrated_vv[i:i+block_size, j:j+block_size] = vv_block\n",
        "                calibrated_vh[i:i+block_size, j:j+block_size] = vh_block\n",
        "    \n",
        "    # Close the datasets\n",
        "    vv_dataset = None\n",
        "    vh_dataset = None\n",
        "    \n",
        "    # Return calibrated VV and VH images as numpy arrays\n",
        "    return calibrated_vv, calibrated_vh"
      ],
      "metadata": {
        "id": "p-Yk2lqL4lNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Applies terrain correction to the VV and VH polarization images.\n",
        "#Returns the terrain-corrected VV and VH images as numpy arrays.\n",
        "\n",
        "\n",
        "def apply_terrain_correction(vv, vh):\n",
        "    # Conversion factor from decibels to power\n",
        "    db_to_power = lambda x: 10 ** (x / 10.0)\n",
        "    \n",
        "    # Terrain height for the given region\n",
        "    terrain_height = 0\n",
        "    \n",
        "    # Apply terrain correction to VV image\n",
        "    vv_tc = db_to_power(vv) / np.sin(np.radians(terrain_height))\n",
        "    vv_db = 10 * np.log10(vv_tc)\n",
        "    \n",
        "    # Apply terrain correction to VH image\n",
        "    vh_tc = db_to_power(vh) / np.sin(np.radians(terrain_height))\n",
        "    vh_db = 10 * np.log10(vh_tc)\n",
        "    \n",
        "    return vv_db, vh_db"
      ],
      "metadata": {
        "id": "tEuACKRQyizV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#optimised version\n",
        "\n",
        "#Applies terrain correction to the VV and VH polarization images.\n",
        "#Returns the terrain-corrected VV and VH images as numpy arrays.\n",
        "\n",
        "def apply_terrain_correction2(vv, vh, block_size=512):\n",
        "    # Conversion factor from decibels to power\n",
        "    db_to_power = lambda x: 10 ** (x / 10.0)\n",
        "    \n",
        "    # Terrain height for the given region\n",
        "    terrain_height = 0\n",
        "    \n",
        "    # Get input array shape\n",
        "    rows, cols = vv.shape\n",
        "    \n",
        "    # Create output arrays\n",
        "    vv_db = np.zeros((rows, cols), dtype=np.float32)\n",
        "    vh_db = np.zeros((rows, cols), dtype=np.float32)\n",
        "    \n",
        "    # Apply terrain correction to each block of the input arrays\n",
        "    for i in range(0, rows, block_size):\n",
        "        for j in range(0, cols, block_size):\n",
        "            vv_block = vv[i:i+block_size, j:j+block_size]\n",
        "            vh_block = vh[i:i+block_size, j:j+block_size]\n",
        "            \n",
        "            # Apply terrain correction to block\n",
        "            vv_tc = db_to_power(vv_block) / np.sin(np.radians(terrain_height))\n",
        "            vh_tc = db_to_power(vh_block) / np.sin(np.radians(terrain_height))\n",
        "            \n",
        "            # Convert back to dB\n",
        "            vv_block_db = 10 * np.log10(vv_tc)\n",
        "            vh_block_db = 10 * np.log10(vh_tc)\n",
        "            \n",
        "            # Save terrain-corrected block to output arrays\n",
        "            vv_db[i:i+block_size, j:j+block_size] = vv_block_db\n",
        "            vh_db[i:i+block_size, j:j+block_size] = vh_block_db\n",
        "    \n",
        "    return vv_db, vh_db"
      ],
      "metadata": {
        "id": "x7qWrihKDOkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Applies a speckle filter to the VV and VH polarization images.\n",
        "#Returns the filtered VV and VH images as numpy arrays.\n",
        "\n",
        "def apply_speckle_filter(vv, vh):\n",
        "    vv_filtered = median(vv)\n",
        "    vh_filtered = median(vh)\n",
        "    \n",
        "    return vv_filtered, vh_filtered\n"
      ],
      "metadata": {
        "id": "dMf-i6Hw3Jke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Saves the VV and VH polarization images as .tif files to the given path.\n",
        "\n",
        "def save_images(vv, vh, path):\n",
        "    # Create output directory if it doesn't exist\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "    \n",
        "    # Define spatial reference and geotransform\n",
        "    crs = rio.crs.CRS.from_epsg(4326)\n",
        "    transform = Affine.identity()\n",
        "    \n",
        "    # Save the processed VV and VH images as .tif files\n",
        "    with rio.open(os.path.join(path, \"vv_processed.tif\"), \"w\", driver=\"GTiff\", height=vv.shape[0], width=vv.shape[1], count=1, dtype=str(vv.dtype), crs=crs, transform=transform, compress=\"deflate\", interleave=\"pixel\") as vv_ds:\n",
        "        vv_ds.write(vv, 1)\n",
        "        \n",
        "    with rio.open(os.path.join(path, \"vh_processed.tif\"), \"w\", driver=\"GTiff\", height=vh.shape[0], width=vh.shape[1], count=1, dtype=str(vh.dtype), crs=crs, transform=transform, compress=\"deflate\", interleave=\"pixel\") as vh_ds:\n",
        "        vh_ds.write(vh, 1)"
      ],
      "metadata": {
        "id": "i5LKTYp6zCqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Before Flood**"
      ],
      "metadata": {
        "id": "dGLGuG1_4e05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#directory\n",
        "file_path = '/content/drive/My Drive/satellite_data/keralabefore/'\n",
        "vv_path = 'S1A_IW_GRDH_1SDV_20180610T004040_20180610T004105_022287_02697B_B830.SAFE/measurement/s1a-iw-grd-vv-20180610t004040-20180610t004105-022287-02697b-001.tiff'\n",
        "vh_path = 'S1A_IW_GRDH_1SDV_20180610T004040_20180610T004105_022287_02697B_B830.SAFE/measurement/s1a-iw-grd-vh-20180610t004040-20180610t004105-022287-02697b-002.tiff'"
      ],
      "metadata": {
        "id": "Ay89n2du4VWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in data\n",
        "vv, vh = read_data(file_path,vv_path,vh_path)"
      ],
      "metadata": {
        "id": "hs8ygvyp7Jmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply radiometric calibration\n",
        "# vv_cal, vh_cal = apply_calibration(vv, vh)\n",
        "vv_cal, vh_cal = apply_calibration2(file_path,vv_path,vh_path)"
      ],
      "metadata": {
        "id": "HA5k3gX3JKY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualisation\n",
        "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 6))\n",
        "ax1.imshow(vv_cal, cmap='gray')\n",
        "ax1.set_title('Calibrated VV')\n",
        "ax1.axis('off')\n",
        "ax2.imshow(vh_cal, cmap='gray')\n",
        "ax2.set_title('Calibrated VH')\n",
        "ax2.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fPx1L3jHRvhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # vv_t,vh_t = apply_terrain_correction(vv_cal,vh_cal)\n",
        "# vv_t,vh_t = apply_terrain_correction2(vv_cal,vh_cal)"
      ],
      "metadata": {
        "id": "90m-PgWlUd1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 6))\n",
        "# ax1.imshow(vv_t, cmap='gray')\n",
        "# ax1.set_title('Corrected Terrain VV')\n",
        "# ax1.axis('off')\n",
        "# ax2.imshow(vh_t, cmap='gray')\n",
        "# ax2.set_title('Corrected Terrain VH')\n",
        "# ax2.axis('off')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "D3uSnNEmSPX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply spekle filter\n",
        "vv_filtered,vh_filtered = apply_speckle_filter(vv_cal,vh_cal)"
      ],
      "metadata": {
        "id": "h1FtTRvLD3rQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 6))\n",
        "ax1.imshow(vv_filtered, cmap='gray')\n",
        "ax1.set_title('Spekle filtered VV')\n",
        "ax1.axis('off')\n",
        "ax2.imshow(vh_filtered, cmap='gray')\n",
        "ax2.set_title('Spekle filtered VH')\n",
        "ax2.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EqvPzQOSURdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_bef = f'{file_path}/processed'"
      ],
      "metadata": {
        "id": "N5o9_A_GXxD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save filtered images\n",
        "save_images(vv_filtered, vh_filtered, save_bef)"
      ],
      "metadata": {
        "id": "cWEHGq9oJQZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **During Flood**"
      ],
      "metadata": {
        "id": "mRHQ1rAjR3gz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#directory\n",
        "file_path1 = '/content/drive/My Drive/satellite_data/keraladuring/'\n",
        "vv_path1 = 'S1A_IW_GRDH_1SDV_20180728T004043_20180728T004108_022987_027EB1_EA20.SAFE/measurement/s1a-iw-grd-vv-20180728t004043-20180728t004108-022987-027eb1-001.tiff'\n",
        "vh_path1 = 'S1A_IW_GRDH_1SDV_20180728T004043_20180728T004108_022987_027EB1_EA20.SAFE/measurement/s1a-iw-grd-vh-20180728t004043-20180728t004108-022987-027eb1-002.tiff'"
      ],
      "metadata": {
        "id": "RBr7-MNrM58I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply radiometric calibration\n",
        "vv_cal1, vh_cal1 = apply_calibration2(file_path1,vv_path1,vh_path1)"
      ],
      "metadata": {
        "id": "gCQ5z2aXekYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 6))\n",
        "ax1.imshow(vv_cal1, cmap='gray')\n",
        "ax1.set_title('Calibrated VV')\n",
        "ax1.axis('off')\n",
        "ax2.imshow(vh_cal1, cmap='gray')\n",
        "ax2.set_title('Calibrated VH')\n",
        "ax2.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qoqBh37we-4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply speckle filter\n",
        "vv_filtered1,vh_filtered1 = apply_speckle_filter(vv_cal1,vh_cal1)"
      ],
      "metadata": {
        "id": "2a1Dq5XGhHKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 6))\n",
        "ax1.imshow(vv_filtered1, cmap='gray')\n",
        "ax1.set_title('Spekle filtered VV')\n",
        "ax1.axis('off')\n",
        "ax2.imshow(vh_filtered1, cmap='gray')\n",
        "ax2.set_title('Spekle filtered VH')\n",
        "ax2.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i83GPCP1htXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_dur = f'{file_path1}/processed'"
      ],
      "metadata": {
        "id": "mv2nr_kxiJe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#saving the outputs\n",
        "save_images(vv_filtered1, vh_filtered1, save_dur)"
      ],
      "metadata": {
        "id": "yIuqpst0iNJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **After Flood**"
      ],
      "metadata": {
        "id": "1e2pqaTckskd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#directory\n",
        "file_path2 = '/content/drive/My Drive/satellite_data/keralaafter/'\n",
        "vv_path2 = 'S1A_IW_GRDH_1SDV_20181020T004046_20181020T004111_024212_02A61E_2CDE.SAFE/measurement/s1a-iw-grd-vv-20181020t004046-20181020t004111-024212-02a61e-001.tiff'\n",
        "vh_path2 = 'S1A_IW_GRDH_1SDV_20181020T004046_20181020T004111_024212_02A61E_2CDE.SAFE/measurement/s1a-iw-grd-vh-20181020t004046-20181020t004111-024212-02a61e-002.tiff'"
      ],
      "metadata": {
        "id": "mzGjY8nzj-MO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply radiometric calibration\n",
        "vv_cal2, vh_cal2 = apply_calibration2(file_path2,vv_path2,vh_path2)"
      ],
      "metadata": {
        "id": "3rqge0AumcxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 6))\n",
        "ax1.imshow(vv_cal2, cmap='gray')\n",
        "ax1.set_title('Calibrated VV')\n",
        "ax1.axis('off')\n",
        "ax2.imshow(vh_cal2, cmap='gray')\n",
        "ax2.set_title('Calibrated VH')\n",
        "ax2.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6DQPJIK4moj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply speckle filter\n",
        "vv_filtered2,vh_filtered2 = apply_speckle_filter(vv_cal2,vh_cal2)"
      ],
      "metadata": {
        "id": "vpf28oyZmvgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 6))\n",
        "ax1.imshow(vv_filtered2, cmap='gray')\n",
        "ax1.set_title('Spekle filtered VV')\n",
        "ax1.axis('off')\n",
        "ax2.imshow(vh_filtered2, cmap='gray')\n",
        "ax2.set_title('Spekle filtered VH')\n",
        "ax2.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uRk5Qq7knJmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_aft = f'{file_path2}/processed'"
      ],
      "metadata": {
        "id": "qNPNmtIbn9hR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#saving the outputs\n",
        "save_images(vv_filtered2, vh_filtered2, save_aft)"
      ],
      "metadata": {
        "id": "AlV2-AQ7pFbt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
